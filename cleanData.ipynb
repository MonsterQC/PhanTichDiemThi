{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and process for a row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"b'<!DOCTYPE html>\", '<html>', '<head>', '    <meta charset=\"utf-8\" />', '    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">', '    <title>Show - S\\\\xe1\\\\xbb\\\\x9f Gi\\\\xc3\\\\xa1o d\\\\xe1\\\\xbb\\\\xa5c v\\\\xc3\\\\xa0 \\\\xc4\\\\x90\\\\xc3\\\\xa0o t\\\\xe1\\\\xba\\\\xa1o TP HCM</title>', '    <link href=\"/Content/css?v=Xso9L40tE7BMv39QjIwZA-y7XWNRBA0m2c4mZornwBo1\" rel=\"stylesheet\"/>', '', '    <script src=\"/bundles/modernizr?v=wBEWDufH_8Md-Pbioxomt90vm6tJN2Pyy9u9zHtWsPo1\"></script>', '', '    <script src=\"/bundles/jquery?v=FVs3ACwOLIVInrAl5sdzR2jrCDmVOWFbZMY6g6Q0ulE1\"></script>', '', '    <script src=\"/bundles/bootstrap?v=2Fz3B0iizV2NnnamQFrx-NbYJNTFeBJ2GM05SilbtQU1\"></script>', '', '    <script src=\"/bundles/jqueryui\"></script>', '', '    <link href=\"/bundles/fonts\" rel=\"stylesheet\"/>', '', '   ', '</head>', '<body>', '    <nav class=\"navbar navbar-inverse\">', '        <div class=\"container-fluid\">', '            <div class=\"navbar-header\">', '                <img style=\"float:left\" src=\"/Images/Logo_so.png\" width=\"85\" />', '<div>', ' <label style=\"margin-top: 12px; color: #eeeeee ; font-size: x-large\">TRA C\\\\xe1\\\\xbb\\\\xa8U \\\\xc4\\\\x90I\\\\xe1\\\\xbb\\\\x82M</label>   ', '<label style=\"color: #eeeeee ; font-size: medium \">K\\\\xe1\\\\xbb\\\\xb2 THI T\\\\xe1\\\\xbb\\\\x90T NGHI\\\\xe1\\\\xbb\\\\x86P TRUNG H\\\\xe1\\\\xbb\\\\x8cC PH\\\\xe1\\\\xbb\\\\x94 TH\\\\xc3\\\\x94NG 2020</label>', '               ', '               ', '</div>', '               ', '            </div>', '           ', '        </div>', '    </nav>', '    ', '   ', '    <div class=\"container body-content\" style=\"margin-top:50px\">', '        ', '', '', '', '', '    <table style=\"margin-top:50px; border: 1px solid; width:100%\">', '        <tr>', '            <td style=\"border: 1px solid ; font-weight: bold \">', '                H\\\\xe1\\\\xbb\\\\x8d v\\\\xc3\\\\xa0 T\\\\xc3\\\\xaan', '            </td>', '            <td style=\"border: 1px solid ; font-weight: bold\">', '                Ng\\\\xc3\\\\xa0y sinh', '            </td>', '            <td style=\"border: 1px solid ; font-weight: bold\">', '                \\\\xc4\\\\x90i\\\\xe1\\\\xbb\\\\x83m thi', '            </td>', '           ', '', '        </tr>', '', '        <tr>', '            <td style=\"border: 1px solid\">', '                PH\\\\xe1\\\\xba\\\\xa0M HO&#192;NG H\\\\xc6\\\\xaf\\\\xc6\\\\xa0NG &#193;I', '            </td>', '            <td style=\"border: 1px solid\">', '                04/11/2002', '            </td>', '            <td style=\"border: 1px solid\">', '                To&#225;n:   6.60   Ng\\\\xe1\\\\xbb\\\\xaf v\\\\xc4\\\\x83n:   6.25   L\\\\xe1\\\\xbb\\\\x8bch s\\\\xe1\\\\xbb\\\\xad:   5.75   \\\\xc4\\\\x90\\\\xe1\\\\xbb\\\\x8ba l&#237;:   7.00   GDCD:   7.25   KHXH: 6.67   Ti\\\\xe1\\\\xba\\\\xbfng Anh:   5.20   ', '            </td>', '', '        </tr>', '', '    </table>', '', '', '', '<br />', '', '', '', '        <br />', '        ', '  ', '</div>', '  ', '   ', '    ', '</body>', '</html>', \"'\\n\"]\n"
     ]
    }
   ],
   "source": [
    "filePath = r\"D:/code/python/data/project-data-science/\"\n",
    "\n",
    "with open(filePath + \"raw_data.txt\", \"r\") as file:\n",
    "    data = file.readline()\n",
    "\n",
    "data = data.split(\"\\\\n\")\n",
    "for i in range(len(data)):\n",
    "    data[i] = data[i].replace(\"\\\\r\", \"\")\n",
    "    data[i] = data[i].replace(\"\\\\t\", \"\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"b'\",\n",
       " 'Show - S\\\\xe1\\\\xbb\\\\x9f Gi\\\\xc3\\\\xa1o d\\\\xe1\\\\xbb\\\\xa5c v\\\\xc3\\\\xa0 \\\\xc4\\\\x90\\\\xc3\\\\xa0o t\\\\xe1\\\\xba\\\\xa1o TP HCM',\n",
       " 'TRA C\\\\xe1\\\\xbb\\\\xa8U \\\\xc4\\\\x90I\\\\xe1\\\\xbb\\\\x82M',\n",
       " 'K\\\\xe1\\\\xbb\\\\xb2 THI T\\\\xe1\\\\xbb\\\\x90T NGHI\\\\xe1\\\\xbb\\\\x86P TRUNG H\\\\xe1\\\\xbb\\\\x8cC PH\\\\xe1\\\\xbb\\\\x94 TH\\\\xc3\\\\x94NG 2020',\n",
       " 'H\\\\xe1\\\\xbb\\\\x8d v\\\\xc3\\\\xa0 T\\\\xc3\\\\xaan',\n",
       " 'Ng\\\\xc3\\\\xa0y sinh',\n",
       " '\\\\xc4\\\\x90i\\\\xe1\\\\xbb\\\\x83m thi',\n",
       " 'PH\\\\xe1\\\\xba\\\\xa0M HO&#192;NG H\\\\xc6\\\\xaf\\\\xc6\\\\xa0NG &#193;I',\n",
       " '04/11/2002',\n",
       " 'To&#225;n:   6.60   Ng\\\\xe1\\\\xbb\\\\xaf v\\\\xc4\\\\x83n:   6.25   L\\\\xe1\\\\xbb\\\\x8bch s\\\\xe1\\\\xbb\\\\xad:   5.75   \\\\xc4\\\\x90\\\\xe1\\\\xbb\\\\x8ba l&#237;:   7.00   GDCD:   7.25   KHXH: 6.67   Ti\\\\xe1\\\\xba\\\\xbfng Anh:   5.20',\n",
       " \"'\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unempty_lines = []\n",
    "\n",
    "for i in range(len(data)):\n",
    "    tags = []\n",
    "    for j in range(len(data[i])):\n",
    "        if data[i][j] == \"<\":\n",
    "            begin = j\n",
    "        if data[i][j] == \">\":\n",
    "            end = j\n",
    "            tags.append(data[i][begin:end+1])\n",
    "            \n",
    "    for tag in tags:\n",
    "        data[i] = data[i].replace(tag, \"\")\n",
    "        \n",
    "    data[i] = data[i].strip()\n",
    "    \n",
    "    if data[i] != \"\":\n",
    "        unempty_lines.append(data[i])\n",
    "        \n",
    "data = unempty_lines\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the neccessary information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PH\\\\xe1\\\\xba\\\\xa0M HO&#192;NG H\\\\xc6\\\\xaf\\\\xc6\\\\xa0NG &#193;I',\n",
       " '04/11/2002',\n",
       " 'To&#225;n:   6.60   Ng\\\\xe1\\\\xbb\\\\xaf v\\\\xc4\\\\x83n:   6.25   L\\\\xe1\\\\xbb\\\\x8bch s\\\\xe1\\\\xbb\\\\xad:   5.75   \\\\xc4\\\\x90\\\\xe1\\\\xbb\\\\x8ba l&#237;:   7.00   GDCD:   7.25   KHXH: 6.67   Ti\\\\xe1\\\\xba\\\\xbfng Anh:   5.20']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = data[7]\n",
    "dob = data[8]\n",
    "scores = data[9]\n",
    "\n",
    "data = [name, dob, scores]\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling special characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phạm Hoàng Hương Ái\n",
      "toán:   6.60   ngữ văn:   6.25   lịch sử:   5.75   địa lí:   7.00   gdcd:   7.25   khxh: 6.67   tiếng anh:   5.20\n"
     ]
    }
   ],
   "source": [
    "with open(filePath + \"unicode.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "    unicode_data = file.read().split(\"\\n\")\n",
    "    \n",
    "chars = []\n",
    "codes = []\n",
    "\n",
    "for unicode in unicode_data:\n",
    "    x = unicode.split(\" \")\n",
    "    chars.append(x[0])\n",
    "    codes.append(x[1])\n",
    "    \n",
    "for i in range(len(chars)):\n",
    "    name = name.replace(codes[i], chars[i])\n",
    "    scores = scores.replace(codes[i], chars[i])\n",
    "    \n",
    "for i in range(len(name)):\n",
    "    if name[i:i+2] == \"&#\":\n",
    "        name = name[:i] + chr(int(name[i+2:i+5])) + name[i+6:]\n",
    "for i in range(len(scores)):\n",
    "    if scores[i:i+2] == \"&#\":\n",
    "        scores = scores[:i] + chr(int(scores[i+2:i+5])) + scores[i+6:]\n",
    "        \n",
    "name = name.title()\n",
    "scores = scores.lower()\n",
    "\n",
    "print(name)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing date of birth, test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Phạm Hoàng Hương Ái', '04', '11', '2002']\n",
      "['toán', '6.60', 'ngữ văn', '6.25', 'lịch sử', '5.75', 'địa lí', '7.00', 'gdcd', '7.25', 'khxh', '6.67', 'tiếng anh', '5.20']\n"
     ]
    }
   ],
   "source": [
    "dob_list = dob.split(\"/\")\n",
    "dd = dob_list[0]\n",
    "mm = dob_list[1]\n",
    "yy = dob_list[2]\n",
    "\n",
    "scores = scores.replace(\":\",\"\")\n",
    "scores = scores.replace(\"khtn \", \"khtn   \")\n",
    "scores = scores.replace(\"khxh \", \"khxh   \")\n",
    "score_list = scores.split(\"   \")\n",
    "\n",
    "data = [name, dd, mm, yy]\n",
    "print(data)\n",
    "print(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add scores to the data in the following order: toán, ngữ văn, lịch sử, địa lí, gdcd, sinh học, vật lí, hóa học, tiếng anh, khtn, khxh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Phạm Hoàng Hương Ái', '04', '11', '2002', '6.60', '6.25', '5.75', '7.00', '7.25', -1, -1, -1, '5.20', -1, '6.67']\n"
     ]
    }
   ],
   "source": [
    "for subject in [\"toán\", \"ngữ văn\", \"lịch sử\", \"địa lí\", \"gdcd\", \"sinh học\", \"vật lí\", \"hóa học\", \"tiếng anh\", \"khtn\", \"khxh\"]:\n",
    "    if subject in score_list:\n",
    "        index = score_list.index(subject) + 1\n",
    "        data.append(score_list[index])\n",
    "    else:\n",
    "        data.append(-1)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read data and process for 74k rows then write to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "filePath = r\"D:/code/python/data/project-data-science/\"\n",
    "\n",
    "with open(\"clean_data.csv\", \"w\", encoding=\"utf8\", newline=\"\") as file_csv:\n",
    "    writer = csv.writer(file_csv)\n",
    "    header = [\"sbd\", \"tên\", \"dd\", \"mm\", \"yy\", \"toán\", \"ngữ văn\", \"lịch sử\", \"địa lí\", \"gdcd\", \"sinh học\", \"vật lí\", \"hóa học\", \"tiếng anh\", \"khtn\", \"khxh\"]\n",
    "    writer.writerow(header)\n",
    "\n",
    "with open(filePath + \"raw_data.txt\", \"r\") as file:\n",
    "    datas = file.read().split(\"\\n\")\n",
    "\n",
    "sbd = 2000000\n",
    "for data in datas:\n",
    "#     try:\n",
    "    sbd +=1\n",
    "    if sbd in [2000521,2002776,2002833,2005380,2005472,2005733,2005820,2005876,2006091,2006300,2006364,2006544,2006712,2006720,2006904,2008746,2009196,2012503,2019593,2020755,2024536,2027212,2031588,2031948,2035434,2036693,2042067,2042972,2043577,2044668,2046177,2046483,2046496,2046651,2046766,2046771,2046788,2046810,2046841,2046998,2047031,2047122,2047241,2047273,2047304,2047486,2047636,2047834,2047843,2047856,2047865,2048225,2048271,2048279,2048397,2048424,2048427,2048592,2048660,2048701,2048723,2048858,2049069,2049090,2049104,2049164,2049234,2049312,2049383,2049663,2049763,2049775,2049891,2049971,2050378,2050476,2050488,2050516,2050526,2050540,2050576,2050642,2050649,2050722,2050809,2050814,2050899,2050959,2050978,2050984,2050985,2051006,2051072,2051181,2051191,2051234,2051422,2051468,2051472,2051495,2051615,2051616,2051736,2052013,2052030,2052089,2052314,2052373,2052591,2052663,2052711,2052791,2052856,2053000,2053106,2053259,2053593,2053699,2053860,2054235,2054306,2054374,2054508,2054733,2054787,2055119,2055200,2055290,2055296,2055606,2055683,2055803,2055829,2055912,2055930,2055986,2056020,2056032,2056105,2056139,2056186,2056190,2056238,2056273,2056291,2056298,2056333,2056350,2056377,2056393,2056782,2056823,2056865,2056871,2057014,2057294,2057410,2057496,2058404,2058498,2058518,2058789,2058938,2059095,2059163,2059740,2059751,2059769,2059774,2059807,2059852,2060462,2060492,2060536,2060610,2060652,2060656,2060660,2060730,2060738,2061813,2062212,2062236,2062391,2062440,2062898,2063109,2063114,2063179,2063180,2063181,2063207,2063272,2063653,2063707,2063716,2063752,2063754,2063825,2064369,2064704,2064783,2064990,2065104,2065323,2065604,2065877,2065995,2066106,2066212,2066835,2067172,2067291,2067316,2067371,2067383,2067401,2067446,2067467,2067550,2067563,2067659,2067672,2067698,2067762,2067909,2067971,2067996,2068089,2068119,2068156,2068174,2068178,2068243,2068287,2068365,2068382,2068427,2068453,2068548,2068550,2068627,2068667,2068702,2068732,2068846,2068970,2069028,2069043,2069066,2069156,2069290,2069362,2069397,2069843,2069990,2070203,2070870,2071102,2071574,2072480,2072549,2072755,2072823,2073036,2073372,2073477,2073556,2073964,2074135,2074254,2074281,2074367,2074607,2074719]:\n",
    "        continue\n",
    "    sbd_str = \"0\" + str(sbd)\n",
    "\n",
    "    data = data.split(\"\\\\n\")\n",
    "\n",
    "    for i in range(len(data)):\n",
    "        data[i] = data[i].replace(\"\\\\r\", \"\")\n",
    "        data[i] = data[i].replace(\"\\\\t\", \"\")\n",
    "\n",
    "# Remove tag  _____________________________________________________________  \n",
    "    unempty_lines = []\n",
    "    for i in range(len(data)):\n",
    "        tags = []\n",
    "        for j in range(len(data[i])):\n",
    "            if data[i][j] == \"<\":\n",
    "                begin = j\n",
    "            if data[i][j] == \">\":\n",
    "                end = j\n",
    "                tags.append(data[i][begin:end+1])\n",
    "        for tag in tags:\n",
    "            data[i] = data[i].replace(tag, \"\")\n",
    "\n",
    "        data[i] = data[i].strip()\n",
    "        if data[i] != \"\":\n",
    "            unempty_lines.append(data[i])\n",
    "\n",
    "    data = unempty_lines\n",
    "\n",
    "# Get the neccessary information ___________________________________________\n",
    "    name = data[7]\n",
    "    dob = data[8]\n",
    "    scores = data[9]\n",
    "    data = [name, dob, scores]\n",
    "\n",
    "# Handling special characters ________________________________________________\n",
    "    with open(filePath + \"unicode.txt\", \"r\", encoding=\"utf8\") as file:\n",
    "        unicode_data = file.read().split(\"\\n\")\n",
    "\n",
    "    chars = []\n",
    "    codes = []\n",
    "    for unicode in unicode_data:\n",
    "        x = unicode.split(\" \")\n",
    "        chars.append(x[0])\n",
    "        codes.append(x[1])\n",
    "    for i in range(len(chars)):\n",
    "        name = name.replace(codes[i], chars[i])\n",
    "        scores = scores.replace(codes[i], chars[i])\n",
    "    for i in range(len(name)):\n",
    "        if name[i:i+2] == \"&#\":\n",
    "            name = name[:i] + chr(int(name[i+2:i+5])) + name[i+6:]\n",
    "    for i in range(len(scores)):\n",
    "        if scores[i:i+2] == \"&#\":\n",
    "            scores = scores[:i] + chr(int(scores[i+2:i+5])) + scores[i+6:]\n",
    "\n",
    "    name = name.title()\n",
    "    scores = scores.lower()\n",
    "\n",
    "# Processing date of birth, test scores ____________________________________________________\n",
    "    dob_list = dob.split(\"/\")\n",
    "    dd = dob_list[0]\n",
    "    mm = dob_list[1]\n",
    "    yy = dob_list[2]\n",
    "    scores = scores.replace(\":\",\"\")\n",
    "    scores = scores.replace(\"khtn \", \"khtn   \")\n",
    "    scores = scores.replace(\"khxh \", \"khxh   \")\n",
    "    score_list = scores.split(\"   \")\n",
    "\n",
    "    data = [sbd_str, name, dd, mm, yy]\n",
    "\n",
    "# Add scores to the data in the following order: toán, ngữ văn, lịch sử, địa lí, gdcd, sinh học, vật lí, hóa học, tiếng anh, khtn, khxh\n",
    "    for subject in [\"toán\", \"ngữ văn\", \"lịch sử\", \"địa lí\", \"gdcd\", \"sinh học\", \"vật lí\", \"hóa học\", \"tiếng anh\", \"khtn\", \"khxh\"]:\n",
    "        if subject in score_list:\n",
    "            index = score_list.index(subject) + 1\n",
    "            data.append(score_list[index])\n",
    "        else:\n",
    "            data.append(-1)\n",
    "\n",
    "# write to csv.file\n",
    "    with open(\"clean_data.csv\", \"a\", encoding=\"utf8\", newline=\"\") as file_csv:\n",
    "        writer = csv.writer(file_csv)\n",
    "        writer.writerow(data)\n",
    "        \n",
    "#     except:\n",
    "#         print(sbd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check data in clean_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(74444, 16)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"clean_data.csv\")\n",
    "data.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
